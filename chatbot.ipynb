{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "846f93ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 [페이지 1] 크롤링 중...\n",
      "🔍 처리 중: [모집공고] 「2025 세계인권도시포럼」안내\n",
      "🔍 처리 중: [장학안내] 2025학년도 여수캠퍼스 학생성공지원금 선발 계획 안내\n",
      "🔍 처리 중: [학사안내] 2024학년도 후기(2025년 8월) 학부 졸업(수료) 예비사...\n",
      "🔍 처리 중: [대학생활] 2025년「CNU나눔-전공연계 국내봉사」참여팀 모집\n",
      "🔍 처리 중: [대학생활] 국제학생증 ISIC 체크카드 무료 발급 행사 안내\n",
      "🔍 처리 중: [학사안내] 2025학년도 하계 계절학기 운영 계획 안내\n",
      "🔍 처리 중: [대학생활] 용봉캠퍼스 교내식당(제1학생마루 학생식당, 햇들마루) 식단가 ...\n",
      "🔍 처리 중: [학사안내] 2024학년도 후기(2025년 8월) 학부 졸업(수료)대상자 ...\n",
      "🔍 처리 중: [대학생활] 2025학년도 1학기 '천원의 아침밥' 제공...\n",
      "🔍 처리 중: [학사안내] 2025학년도 신(편)입생 학생증(스마트카드) 발급 신청 안내\n",
      "🔍 처리 중: [대학생활] 2025학년도 대학생활안내\n",
      "🔍 처리 중: [학사안내] 2025학년도 1학기 교양교과목 편성 목록 안내\n",
      "🔍 처리 중: [학사안내] 2025학년도 제1학기 휴학·복학 신청 안내\n",
      "🔍 처리 중: [모집공고] 2025-2026학년도 전남대 해외 파견프로그램 선발 일정\n",
      "🔍 처리 중: [모집공고] 『2025 대한민국 열린 토론대회』 논제 공모\n",
      "🔍 처리 중: [공모전] 기술보증기금 「2025년도 대국민 혁신 아이디어 공모전」안내\n",
      "🔍 처리 중: [공모전] 「2025 날씨 빅데이터 콘테스트」 개최 알림\n",
      "🔍 처리 중: [공모전] 2025년 IP 아카데미 카드뉴스 공모전 안내\n",
      "🔍 처리 중: [공모전] 「2025년 대국민 농식품 규제혁신 공모전」개최 알림\n",
      "🔍 처리 중: [취업정보] [농업정책보험금융원] 2025 농업정책보험금융원 제3차 직원 ...\n",
      "\n",
      "✅ 총 20개의 공지 수집 완료!\n",
      "\n",
      "[모집공고] 「2025 세계인권도시포럼」안내\n",
      "🔗 https://www.jnu.ac.kr/WebApp/web/HOM/COM/Board/board.aspx?boardID=5&bbsMode=view&page=1&key=65952\n",
      "「2025 세계인권도시포럼」안내  광주광역시는 2011년부터 ‘인권도시 광주’의 비전을 실현하기 위해 매년 세계인권도시포럼을 개최하고 있습니다. 아래와 같이 「2025 세계인권도시... \n",
      "\n",
      "[장학안내] 2025학년도 여수캠퍼스 학생성공지원금 선발 계획 안내\n",
      "🔗 https://www.jnu.ac.kr/WebApp/web/HOM/COM/Board/board.aspx?boardID=5&bbsMode=view&page=1&key=65906\n",
      "2025학년도 여수캠퍼스 학생성공지원금 선발 계획을 다음과 같이 안내하오니 많은 지원 바라며, 지원서 접수 전 붙임 문서를 반드시 숙지하신 후 전남대학교 포털사이트를 통하여 온라인... \n",
      "\n",
      "[학사안내] 2024학년도 후기(2025년 8월) 학부 졸업(수료) 예비사...\n",
      "🔗 https://www.jnu.ac.kr/WebApp/web/HOM/COM/Board/board.aspx?boardID=5&bbsMode=view&page=1&key=65905\n",
      "□ 2024학년도 후기(2025년 8월) 학부 졸업(수료) 예비사정 실시 안내 □  2024학년도 후기(2025년 8월) 학부 졸업(수료) 예비사정을 다음과 같이 실시하니, 해당 ... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 전남대학교 공지사항 크롤러\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = '/opt/homebrew/bin/tesseract'\n",
    "os.environ['TESSDATA_PREFIX'] = '/opt/homebrew/share/tessdata'\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\") \n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# 유효한 카테고리 정의\n",
    "valid_categories = [\"학사안내\", \"대학생활\", \"모집공고\", \"공모전\", \"채용공고\", \"취업정보\", \"장학안내\", \"병무안내\"]\n",
    "\n",
    "# 크롤링된 데이터 저장 리스트\n",
    "data = []\n",
    "\n",
    "# 포털 기본 주소\n",
    "base_url = \"https://www.jnu.ac.kr\"\n",
    "\n",
    "# 페이지 범위 설정\n",
    "for page in range(1, 2):\n",
    "    print(f\"📄 [페이지 {page}] 크롤링 중...\")\n",
    "    url = f\"https://www.jnu.ac.kr/WebApp/web/HOM/COM/Board/board.aspx?boardID=5&bbsMode=list&cate=0&page={page}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 전남대 홈페이지 공지사항에서 제목 태그\n",
    "    notice_elements = driver.find_elements(By.CSS_SELECTOR, \"td.title > a\")\n",
    "    \n",
    "    # 홈페이지 제목수집\n",
    "    notices_to_process = []\n",
    "    for el in notice_elements:\n",
    "        try:\n",
    "            full_title = el.text.strip()\n",
    "            relative_link = el.get_attribute(\"href\")\n",
    "            link = relative_link \n",
    "            match = re.match(r\"\\[(.*?)\\]\\s*(.*)\", full_title)\n",
    "            # 카테고리 별 분류\n",
    "            if match:\n",
    "                category = match.group(1)\n",
    "                title = match.group(2)\n",
    "            else:\n",
    "                category = \"기타\"\n",
    "                title = full_title\n",
    "                \n",
    "            if category not in valid_categories:\n",
    "                category = \"기타\"\n",
    "                \n",
    "            notices_to_process.append({\n",
    "                \"category\": category,\n",
    "                \"title\": title,\n",
    "                \"link\": link\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 제목/링크 추출 실패: {e}\")\n",
    "    \n",
    "    # 수집된 링크를 하나씩 방문하여 내용 크롤링\n",
    "    for notice in notices_to_process:\n",
    "        try:\n",
    "            print(f\"🔍 처리 중: [{notice['category']}] {notice['title']}\")\n",
    "            driver.get(notice['link'])\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # 본문 텍스트 수집\n",
    "            try:\n",
    "                text_content = driver.find_element(By.CLASS_NAME, \"view_body\").text.strip()\n",
    "                text_content = text_content.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 본문 텍스트 추출 실패: {e}\")\n",
    "                text_content = \"\"\n",
    "            \n",
    "            # 이미지 OCR 텍스트 수집\n",
    "            ocr_text = \"\"\n",
    "            try:\n",
    "                images = driver.find_elements(By.CSS_SELECTOR, \".view_body img\")\n",
    "                for img in images:\n",
    "                    img_url = img.get_attribute(\"src\")\n",
    "                    if not img_url.startswith(\"http\"):\n",
    "                        img_url = base_url + img_url\n",
    "                    \n",
    "                    try:\n",
    "                        response = requests.get(img_url)\n",
    "                        image = Image.open(BytesIO(response.content))\n",
    "                        \n",
    "                        ocr_text += pytesseract.image_to_string(image, lang=\"kor\") + \"\\n\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ 이미지 OCR 실패: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 이미지 요소 찾기 실패: {e}\")\n",
    "            \n",
    "            # 수집한 내용 저장\n",
    "            content = text_content + \"\\n\" + ocr_text.strip()\n",
    "            notice[\"content\"] = content\n",
    "            data.append(notice)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 공지 크롤링 실패: {e}\")\n",
    "driver.quit()\n",
    "\n",
    "# ✅ 결과 확인 \n",
    "print(f\"\\n✅ 총 {len(data)}개의 공지 수집 완료!\\n\")\n",
    "for notice in data[:3]:\n",
    "    print(f\"[{notice['category']}] {notice['title']}\")\n",
    "    print(f\"🔗 {notice['link']}\")\n",
    "    print(notice['content'][:100] + \"...\" if notice['content'] else \"내용 없음\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# langchain을 활용하여 데이터 청킹 \n",
    "def chunk_documents(data, chunk_size=150, chunk_overlap=25):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    chunked_documents = []\n",
    "\n",
    "    for item in data:\n",
    "        metadata = {\n",
    "            \"category\": item.get(\"category\", \"\"),\n",
    "            \"title\": item.get(\"title\", \"\"),\n",
    "            \"link\": item.get(\"link\", \"\"),\n",
    "            \"source_id\": item.get(\"id\", \"\") if \"id\" in item else f\"{item.get('title', '')[:20]}\"\n",
    "        }\n",
    "\n",
    "        title = item.get(\"title\", \"\")\n",
    "        category = item.get(\"category\", \"\")\n",
    "        content = item.get(\"content\", \"\")\n",
    "        link = item.get(\"link\", \"\")\n",
    "\n",
    "        if content:\n",
    "            content_chunks = text_splitter.split_text(content)\n",
    "\n",
    "            for i, chunk in enumerate(content_chunks):\n",
    "                # 방식 1번 : full_chunk = chunk\n",
    "                # 방식 2번 : category + title + chunk 조합\n",
    "                full_chunk = f\"[{category}] {title} - {chunk}\"\n",
    "                # full_chunk += f\" (출처: {link})\"\n",
    "                \n",
    "                doc = Document(\n",
    "                    page_content=full_chunk,\n",
    "                    metadata={\n",
    "                        **metadata,\n",
    "                        \"chunk_id\": i,\n",
    "                        \"chunk_count\": len(content_chunks)\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                chunked_documents.append(doc)\n",
    "        else:\n",
    "            full_chunk = f\"[{category}] {title}\"\n",
    "            doc = Document(\n",
    "                page_content=full_chunk,\n",
    "                metadata=metadata\n",
    "            )\n",
    "            chunked_documents.append(doc)\n",
    "\n",
    "    return chunked_documents\n",
    "\n",
    "\n",
    "\n",
    "# 한국어 전용 SBERT 모델 로딩\n",
    "embedding_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# 예시 임베딩 함수\n",
    "def embed_documents(docs):\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    embeddings = embedding_model.encode(texts, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2e464e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.84016085, -0.01643609, -0.23869938, ..., -0.4581829 ,\n",
       "        -0.19099139,  0.24905178],\n",
       "       [-1.0638907 , -0.20040065, -0.00766017, ...,  0.07699399,\n",
       "         0.26231852,  0.03336357],\n",
       "       [-0.8535307 , -0.54984456,  0.20781986, ..., -0.05521315,\n",
       "        -0.30920595, -0.07586239],\n",
       "       ...,\n",
       "       [-0.4667073 , -0.37870374, -0.7335357 , ...,  0.571243  ,\n",
       "         0.49001592, -0.20996752],\n",
       "       [ 0.24263811, -0.2938347 , -0.6003033 , ...,  0.45064425,\n",
       "         0.6354364 , -0.45687437],\n",
       "       [-1.0110147 , -0.17097613, -0.94552153, ...,  0.2176166 ,\n",
       "         0.18630247, -0.05454658]], shape=(346, 768), dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs = chunk_documents(data)\n",
    "embed_documents(chunked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 문서 내부 유사도 (intra-document avg)\n",
      "방식1 평균: 0.7137\n",
      "\n",
      "✅ 문서 간 유사도 (inter-document avg)\n",
      "방식1 평균: 0.5358\n"
     ]
    }
   ],
   "source": [
    "# 유사도 계산하기\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def group_by_source(docs):\n",
    "    groups = defaultdict(list)\n",
    "    for i, doc in enumerate(docs):\n",
    "        groups[doc.metadata['source_id']].append(i)\n",
    "    return groups\n",
    "\n",
    "def get_avg_intra_doc_similarity(docs, embeddings):\n",
    "    groups = group_by_source(docs)\n",
    "    result = {}\n",
    "    for source_id, indices in groups.items():\n",
    "        if len(indices) < 2:\n",
    "            continue\n",
    "        sims = []\n",
    "        for i in range(len(indices)):\n",
    "            for j in range(i + 1, len(indices)):\n",
    "                sim = cosine_similarity([embeddings[indices[i]]], [embeddings[indices[j]]])[0][0]\n",
    "                sims.append(sim)\n",
    "        result[source_id] = np.mean(sims)\n",
    "    return result\n",
    "\n",
    "def get_avg_inter_doc_similarity(docs, embeddings):\n",
    "    groups = group_by_source(docs)\n",
    "    doc_ids = list(groups.keys())\n",
    "    sims = []\n",
    "    for i in range(len(doc_ids)):\n",
    "        for j in range(i + 1, len(doc_ids)):\n",
    "            idx1 = groups[doc_ids[i]][0]\n",
    "            idx2 = groups[doc_ids[j]][0]\n",
    "            sim = cosine_similarity([embeddings[idx1]], [embeddings[idx2]])[0][0]\n",
    "            sims.append(sim)\n",
    "    return np.mean(sims)\n",
    "\n",
    "# 계산\n",
    "intra1 = get_avg_intra_doc_similarity(chunked_docs, embed_documents)\n",
    "inter1 = get_avg_inter_doc_similarity(chunked_docs, embed_documents)\n",
    "\n",
    "print(\"✅ 문서 내부 유사도 (intra-document avg)\")\n",
    "print(f\"방식2 평균: {np.mean(list(intra1.values())):.4f}\")\n",
    "# print(f\"방식1 평균: {np.mean(list(intra2.values())):.4f}\")\n",
    "\n",
    "print(\"\\n✅ 문서 간 유사도 (inter-document avg)\")\n",
    "print(f\"방식2 평균: {inter1:.4f}\")\n",
    "# print(f\"방식1 평균: {inter2:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbdef6",
   "metadata": {},
   "source": [
    "## 결과\n",
    "✅ 문서 내부 유사도 (intra-document avg)\n",
    "청크 방식1 평균: 0.4946\n",
    "청크 방식2 평균: 0.7137\n",
    "\n",
    "✅ 문서 간 유사도 (inter-document avg)\n",
    "청크 방식1 평균: 0.4169\n",
    "청크 방식2 평균: 0.5358\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955bf922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ jnu-notice 인덱스가 이미 존재합니다. 삭제 후 재생성합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 100개 업로드됨\n",
      "✅ 200개 업로드됨\n",
      "✅ 300개 업로드됨\n",
      "✅ 346개 업로드됨\n",
      "✅ Pinecone 업로드 완료! <pinecone.data.index.Index object at 0x3145dba90>\n"
     ]
    }
   ],
   "source": [
    "# Pinecone 디비 업로드\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Pinecone 클라이언트 초기화\n",
    "embedding_model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "\n",
    "\n",
    "# 청킹한 데이터 임베딩 후 Pinecone 업로드\n",
    "def upload_documents(docs, index_name=INDEX_NAME):\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(index_name)\n",
    "    \n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f\"⚠️ {index_name} 인덱스가 이미 존재합니다. 삭제 후 재생성합니다.\")\n",
    "        pc.delete_index(index_name)\n",
    "\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    \n",
    "    # 임베딩\n",
    "    embeddings = embedding_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "    # 임베드 된 정보와 해당 내용 같이 업로드\n",
    "    vectors = [\n",
    "        (f\"id_{i}\", emb.tolist(), {\"text\": texts[i]})\n",
    "        for i, emb in enumerate(embeddings)\n",
    "    ]\n",
    "\n",
    "    for i in range(0, len(vectors), 100):\n",
    "        index.upsert(vectors=vectors[i:i+100])\n",
    "        print(f\"✅ {i+len(vectors[i:i+100])}개 업로드됨\")\n",
    "\n",
    "    return index\n",
    "\n",
    "uploaded_index = upload_documents(chunked_docs, index_name=INDEX_NAME)\n",
    "\n",
    "print(\"✅ Pinecone 업로드 완료!\",uploaded_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc40d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📢 Gemini 응답:\n",
      "안녕하세요! 휴학을 원하시는군요.  😊\n",
      "\n",
      "2025학년도 1학기 휴학 신청 기간은  휴학 종류에 따라 다르네요.  자세한 내용은 아래와 같아요.\n",
      "\n",
      "* **일반휴학(등록):** 2025년 2월 18일(화) ~ 4월 24일(목)  (등록금 납부 후 휴학을 원하는 경우)\n",
      "* **일반휴학(미등록):** 2025년 2월 18일(화) ~ 2월 21일(금) (등록금 납부 전 휴학을 원하는 경우)\n",
      "* **군휴학(복무신고):** 입영일 한 달 전 ~ 입영일 (학기 중 군입대 예정인 경우)\n",
      "* **질병휴학:** 사유 발생 시 ~ 종강일 (진단서 필요)\n",
      "* **임신·출산·육아휴학:** 사유 발생 시 ~ 종강일 (관련 서류 필요)\n",
      "* **창업휴학(등록):** 2025년 2월 18일(화) ~ 4월 24일(목)\n",
      "\n",
      "자신의 상황에 맞는 휴학 종류를 확인하시고, 해당 기간 내에 신청하시는 것을 잊지 마세요!  혹시 다른 궁금한 점이 있다면 단과대학 행정실이나 학과(부)실에 문의하시면 친절하게 안내받으실 수 있을 거예요.  😄\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "# 언어모델 연결\n",
    "\n",
    "# Gemini 설정\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "\n",
    "# Gemini 질문하기\n",
    "def query_with_gemini(index, query, top_k=10):\n",
    "    try:\n",
    "        # 임베딩\n",
    "        query_embedding = embedding_model.encode(query).tolist()\n",
    "        \n",
    "        # Pinecone 검색\n",
    "        search_results = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        matches = search_results.get(\"matches\", [])\n",
    "        if not matches:\n",
    "            return \"🔍 검색 결과가 없습니다. 질문이 너무 구체적이거나 관련 문서가 없을 수 있어요.\"\n",
    "        # 검색된 문서 추출\n",
    "        retrieved_chunks = [\n",
    "            match['metadata']['text']\n",
    "            for match in matches\n",
    "            if match.get('metadata') and match['metadata'].get('text')\n",
    "        ]\n",
    "        \n",
    "        # 최대 길이 제한 (Gemini 입력 길이 방지)\n",
    "        context_text = \"\\n\\n\".join(retrieved_chunks)[:10000]\n",
    "\n",
    "        # 프롬프트 구성\n",
    "        prompt = f\"\"\"\n",
    "🔎 [문서 검색 결과 요약]:\n",
    "다음은 '{query}'에 대해 검색된 문서 조각들입니다.\n",
    "\n",
    "{context_text}\n",
    "\n",
    "🧠 [당신의 역할]:\n",
    "- 당신은 지식 기반의 정보를 바탕으로 정확하고 신뢰성 있는 답변을 제공하는 전문가입니다.\n",
    "\n",
    "📌 [답변 지침]:\n",
    "1. 문서에 관련 내용이 **명확히 포함되어 있다면**, 그 내용을 인용해 답변하세요.\n",
    "2. **직접적인 정보가 없더라도**, 문서 맥락을 분석하여 가능한 **추론/해석**을 시도해 주세요.\n",
    "3. 답변은 정확하되, **친절하고 자연스러운 한국어**로 설명해 주세요.\n",
    "4. 답변과 전혀 관련 없는 내용은 생략해주세요\n",
    "5. \"제공된 자료에는*, 문서에는* \" 으로 시작하지 말아줘.\n",
    "6. 너무 딱딱하지 않게 , 친절하고 대화하듯 \"*요\"로 마무리 해줘.\n",
    "7. 가독성이 좋게 각 문장들을 줄바꿈 해줘. \n",
    "8. 문서에 적절한 이모티콘을 넣어 읽기 쉽게 만들어줘.\n",
    "\n",
    "❓ [질문]:\n",
    "{query}\n",
    "\n",
    "📝 [답변]:\n",
    "\"\"\"\n",
    "        # Gemini 응답 생성\n",
    "        response = gemini_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                candidate_count=1,\n",
    "                temperature=0.8\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return response.text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"⚠️ 오류 발생: {str(e)}\"\n",
    "\n",
    "\n",
    "# ✅ 실제 실행\n",
    "# query = \"취업 관련 공고가 있나?\"\n",
    "# query = \"졸업 유보를 하고싶은데, 유보의 조건\"\n",
    "query = \"휴학을 하고 싶어. 휴학 신청 기간 알려줘.\"\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(INDEX_NAME)\n",
    "answer = query_with_gemini(uploaded_index, query)\n",
    "\n",
    "print(\"\\n📢 Gemini 응답:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1302caa5",
   "metadata": {},
   "source": [
    "# 피드백\n",
    "최종 발표까지 이화여대 챗봇(타겟서비스) 차별성 구체화해오기 + 현재 이화여대 챗봇이 업데이트가 안되고 있는데 친구한테 실제 이화여대 학생들이 사용하고있는지 물어보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
